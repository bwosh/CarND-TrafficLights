{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLA-34 in Keras with HSwish as option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, Input, MaxPool2D\n",
    "from keras.activations import relu\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "    \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReLU, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ReLU, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.relu(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "class HSwish(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(HSwish, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(HSwish, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        six = K.ones_like(x)*6\n",
    "        return x* K.minimum(K.relu(x+3),six)/6\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    def __init__(self, name):\n",
    "        self.root = None\n",
    "        self.tree1 = None\n",
    "        self.tree2 = None\n",
    "        self.level_root = None\n",
    "        self.root_dim = None\n",
    "        self.downsample = None\n",
    "        self.project = None\n",
    "        self.levels = None\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "    def __print_indent(self, indent, text, end='\\n'):\n",
    "        print( \"\".join([' ']*indent), end='')\n",
    "        print(text, end = end)\n",
    "              \n",
    "    def print(self, indent = 0):\n",
    "        self.__print_indent(1 if indent>0 else 0, \"[NODE: \"+str(self.name), end=' ')\n",
    "        self.__print_indent(0, \"lr:\"+str(self.level_root), end=' ')\n",
    "        self.__print_indent(0, \"rdim:\"+str(self.root_dim), end=' ')\n",
    "        self.__print_indent(0, \"downs: \"+str(self.downsample==None), end=' ')\n",
    "        self.__print_indent(0, \"proj: \"+str(self.project==None), end=' ')\n",
    "        self.__print_indent(0, \"levs: \"+str(self.levels), end=']\\n')\n",
    "        \n",
    "        if self.root is None:\n",
    "              self.__print_indent(indent+2, \"R1> None\")\n",
    "        else:\n",
    "              self.__print_indent(indent+2, \"R1> conv,bn,act \")\n",
    "              \n",
    "        if isinstance(self.tree1,Tree):\n",
    "            self.__print_indent(indent+2, \"T1>\", end='')\n",
    "            self.tree1.print(indent=indent+4)\n",
    "        elif self.tree1 is not None:\n",
    "            self.__print_indent(indent+2, \"T1> conv,bn\")\n",
    "\n",
    "        if isinstance(self.tree2,Tree):\n",
    "            self.__print_indent(indent+2, \"T2>\", end='')\n",
    "            self.tree2.print(indent=indent+4)\n",
    "        elif self.tree2 is not None:\n",
    "            self.__print_indent(indent+2, \"T2> conv,bn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DlaKeras():\n",
    "    def __init__(self, input_shape = (512,512,3),  \n",
    "                 levels=[1, 1, 1, 2, 2, 1],\n",
    "                 planes=[16, 32, 64, 128, 256, 512],\n",
    "                 data_format = \"NHWC\", activation_function=\"relu\", debug=False):\n",
    "        self.norm_axis = 1 if data_format ==\"NCHW\" else -1\n",
    "        self.input = Input(shape = input_shape)\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "        self.base_layer = self._make_simple_block(planes[0], kernel_size=7)\n",
    "        self.level0 = self._make_conv_level(planes[0], levels[0], stride=1)\n",
    "        self.level1 = self._make_conv_level(planes[1], levels[1], stride=2)\n",
    "        \n",
    "        self.level2 = self._make_tree(\"L2_\", levels[2], planes[1], planes[2], level_root=False)\n",
    "        self.level3 = self._make_tree(\"L3_\",levels[3], planes[2], planes[3])\n",
    "        self.level4 = self._make_tree(\"L4_\",levels[4], planes[3], planes[4])\n",
    "        self.level5 = self._make_tree(\"L5_\",levels[5], planes[4], planes[5])\n",
    "        \n",
    "        self.debug = debug\n",
    "        if debug:\n",
    "            self.level2.print()\n",
    "            self.level3.print()\n",
    "            self.level4.print()\n",
    "            self.level5.print()\n",
    "        \n",
    "    def _make_tree(self, name, levels, in_planes, planes, stride=2, level_root=True, root_dim=0):\n",
    "        result = Tree(name)\n",
    "        \n",
    "        if root_dim == 0:\n",
    "            root_dim = 2 * planes\n",
    "        if level_root:\n",
    "            root_dim += in_planes\n",
    "        \n",
    "        if levels==1:\n",
    "            result.tree1 = self._make_basic_block(planes, stride)\n",
    "            result.tree2 = self._make_basic_block(planes, 1)\n",
    "        else:\n",
    "            result.tree1 = self._make_tree(name+\"1\",levels-1, in_planes, planes, stride=stride)\n",
    "            result.tree2 = self._make_tree(name+\"2\",levels-1, planes, planes, stride=1, root_dim=root_dim + planes)\n",
    "            \n",
    "        if levels == 1:\n",
    "            result.root = self._make_root(root_dim, planes)   # TODO minor: remove root_dim ?\n",
    "        \n",
    "        result.level_root = level_root\n",
    "        result.root_dim = root_dim\n",
    "        result.levels = levels\n",
    "        if stride > 1:\n",
    "            result.downsample = MaxPool2D(pool_size=(stride, stride), strides=(stride, stride), padding = 'same')\n",
    "            \n",
    "        if in_planes != planes:\n",
    "            result.project = []\n",
    "            result.project.append(Conv2D(filters=planes, kernel_size=1, padding='same', strides=(1,1), use_bias=False))\n",
    "            result.project.append(BatchNormalization(axis=self.norm_axis))    \n",
    "\n",
    "        return result\n",
    "\n",
    "    def _make_root(self, in_planes, planes):\n",
    "        return self._make_simple_block(planes)\n",
    "    \n",
    "    def _make_basic_block(self, planes, stride=1):\n",
    "        layers=[]\n",
    "        \n",
    "        conv1 = Conv2D(filters=planes, kernel_size=3, padding='same', strides=(stride,stride), use_bias=False)\n",
    "        bn1 = BatchNormalization(axis=self.norm_axis)\n",
    "        if self.activation_function == \"hswish\":\n",
    "            activation = HSwish()\n",
    "        else:\n",
    "            activation = ReLU()\n",
    "        conv2 = Conv2D(filters=planes, kernel_size=3, padding='same', strides=(1,1), use_bias=False)\n",
    "        bn2 = BatchNormalization(axis=self.norm_axis)\n",
    "        \n",
    "        layers = [conv1,bn1,activation, conv2, bn2]\n",
    "        return layers\n",
    "    \n",
    "    def _make_simple_block(self, planes, kernel_size=3, stride = 1):\n",
    "        \n",
    "        conv = Conv2D(filters=planes, kernel_size=kernel_size, padding='same', strides=(stride,stride), use_bias=False)\n",
    "        bn = BatchNormalization(axis=self.norm_axis)\n",
    "        if self.activation_function == \"hswish\":\n",
    "            activation = HSwish()\n",
    "        else:\n",
    "            activation = ReLU()\n",
    "        \n",
    "        layers = [conv,bn,activation]\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def _make_conv_level(self, planes, levels, stride = 1):\n",
    "        layers = []\n",
    "        for i in range(levels):\n",
    "            layers.extend(self._make_simple_block(planes, stride = stride))\n",
    "        return layers\n",
    "            \n",
    "    def _build_list(self, x, layers):\n",
    "        for l in layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "    \n",
    "    def _build_root(self, root, *x):\n",
    "        x = list(x)\n",
    "        conv = root[0]\n",
    "        bn = root[1]\n",
    "        act = root[2]\n",
    "        \n",
    "        #print(\"--\", len(x))\n",
    "        #for i in x:\n",
    "            #print(i.shape)\n",
    "        #print(\"---\")\n",
    "        \n",
    "        x = concatenate(x, axis = self.norm_axis)\n",
    "        #print(\"Concatenated: \",x.shape)\n",
    "        x = conv(x)\n",
    "        x = bn(x)\n",
    "        x = act(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _build_tree(self,x, tree, children=None, residual=None):\n",
    "        if not isinstance(tree, Tree):\n",
    "            return self._build_list(x,tree)\n",
    "        \n",
    "        #print(\"\\nCALL:\"+tree.name)\n",
    "        #print(\"input shape:\", x.shape)\n",
    "        \n",
    "        children = [] if children is None else children\n",
    "        #print(\"children\", len(children))\n",
    "        #print(\"bottom before\", x.shape)\n",
    "        bottom = tree.downsample(x) if tree.downsample else x\n",
    "        #print(\"bottom after\", bottom.shape)\n",
    "        \n",
    "        #print(\"residual before\", bottom.shape)\n",
    "        residual = self._build_list(bottom,tree.project) if tree.project else bottom\n",
    "        #print(\"residual after\", residual.shape)\n",
    "        \n",
    "        if tree.level_root:\n",
    "            children.append(bottom)\n",
    "\n",
    "        x1 = self._build_tree(x, tree.tree1, residual=residual)\n",
    "\n",
    "        if tree.levels == 1:\n",
    "            x2 = self._build_tree(x1,tree.tree2)\n",
    "            x = self._build_root(tree.root, x2, x1, *children)\n",
    "        else:\n",
    "            children.append(x1)\n",
    "            x = self._build_tree(x1, tree.tree2, children=children)\n",
    "        return x\n",
    "        \n",
    "    def build(self):\n",
    "        inputs = self.input\n",
    "\n",
    "        x = self._build_list(inputs, self.base_layer)\n",
    "        #print(\"## After base layer\",x.shape)\n",
    "        x = self._build_list(x, self.level0)\n",
    "        #print(\"## After lev0 layer\",x.shape)\n",
    "        x = self._build_list(x, self.level1)\n",
    "        #print(\"## After lev1 layer\",x.shape)\n",
    "        x = self._build_tree(x, self.level2)\n",
    "        #print(\"## After lev2 layer\",x.shape)\n",
    "        x = self._build_tree(x, self.level3)\n",
    "        #print(\"## After lev3 layer\",x.shape)\n",
    "        x = self._build_tree(x, self.level4)\n",
    "        #print(\"## After lev4 layer\",x.shape)\n",
    "        x = self._build_tree(x, self.level5)\n",
    "        #print(\"## After lev5 layer\",x.shape)\n",
    "        #TODO clean the debug comemnted code when done\n",
    "        return Model(inputs = inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NODE: L2_ lr:False rdim:128 downs: False proj: False levs: 1]\n",
      "  R1> conv,bn,act \n",
      "  T1> conv,bn\n",
      "  T2> conv,bn\n",
      "[NODE: L3_ lr:True rdim:320 downs: False proj: False levs: 2]\n",
      "  R1> None\n",
      "  T1> [NODE: L3_1 lr:True rdim:320 downs: False proj: False levs: 1]\n",
      "      R1> conv,bn,act \n",
      "      T1> conv,bn\n",
      "      T2> conv,bn\n",
      "  T2> [NODE: L3_2 lr:True rdim:576 downs: True proj: True levs: 1]\n",
      "      R1> conv,bn,act \n",
      "      T1> conv,bn\n",
      "      T2> conv,bn\n",
      "[NODE: L4_ lr:True rdim:640 downs: False proj: False levs: 2]\n",
      "  R1> None\n",
      "  T1> [NODE: L4_1 lr:True rdim:640 downs: False proj: False levs: 1]\n",
      "      R1> conv,bn,act \n",
      "      T1> conv,bn\n",
      "      T2> conv,bn\n",
      "  T2> [NODE: L4_2 lr:True rdim:1152 downs: True proj: True levs: 1]\n",
      "      R1> conv,bn,act \n",
      "      T1> conv,bn\n",
      "      T2> conv,bn\n",
      "[NODE: L5_ lr:True rdim:1280 downs: False proj: False levs: 1]\n",
      "  R1> conv,bn,act \n",
      "  T1> conv,bn\n",
      "  T2> conv,bn\n",
      "Output shape calculated: (1, 16, 16, 512)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 512, 512, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 512, 512, 16)  2352        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 512, 512, 16)  64          conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_1 (HSwish)               (None, 512, 512, 16)  0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 512, 512, 16)  2304        h_swish_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 512, 512, 16)  64          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_2 (HSwish)               (None, 512, 512, 16)  0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 256, 256, 32)  4608        h_swish_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 256, 256, 32)  128         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_3 (HSwish)               (None, 256, 256, 32)  0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 128, 128, 64)  18432       h_swish_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 128, 128, 64)  256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_4 (HSwish)               (None, 128, 128, 64)  0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 128, 128, 64)  36864       h_swish_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 128, 128, 64)  256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 128, 128, 64)  36864       batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 128, 128, 64)  256         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_5 (HSwish)               (None, 128, 128, 64)  0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 128, 128, 64)  36864       h_swish_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 128, 128, 64)  256         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 128, 128, 128) 0           batch_normalization_7[0][0]      \n",
      "                                                                   batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 128, 128, 64)  73728       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 128, 128, 64)  256         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_6 (HSwish)               (None, 128, 128, 64)  0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 64, 64, 128)   73728       h_swish_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 64, 64, 128)   512         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_7 (HSwish)               (None, 64, 64, 128)   0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 64, 64, 128)   147456      h_swish_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 64, 64, 128)   512         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 64, 64, 128)   147456      batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 64, 64, 128)   512         conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_8 (HSwish)               (None, 64, 64, 128)   0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 64, 64, 128)   147456      h_swish_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 64, 64, 128)   512         conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 64, 64, 64)    0           h_swish_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 64, 64, 320)   0           batch_normalization_13[0][0]     \n",
      "                                                                   batch_normalization_11[0][0]     \n",
      "                                                                   max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 64, 64, 128)   368640      concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 64, 64, 128)   512         conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_9 (HSwish)               (None, 64, 64, 128)   0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 64, 64, 128)   147456      h_swish_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 64, 64, 128)   512         conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_10 (HSwish)              (None, 64, 64, 128)   0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 64, 64, 128)   147456      h_swish_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 64, 64, 128)   512         conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 64, 64, 128)   147456      batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 64, 64, 128)   512         conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_11 (HSwish)              (None, 64, 64, 128)   0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 64, 64, 128)   147456      h_swish_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 64, 64, 128)   512         conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 64, 64, 64)    0           h_swish_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 64, 64, 576)   0           batch_normalization_19[0][0]     \n",
      "                                                                   batch_normalization_17[0][0]     \n",
      "                                                                   max_pooling2d_3[0][0]            \n",
      "                                                                   h_swish_9[0][0]                  \n",
      "                                                                   h_swish_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 64, 64, 128)   663552      concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 64, 64, 128)   512         conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_12 (HSwish)              (None, 64, 64, 128)   0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 32, 32, 256)   294912      h_swish_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 32, 32, 256)   1024        conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_13 (HSwish)              (None, 32, 32, 256)   0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 32, 32, 256)   589824      h_swish_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 32, 32, 256)   1024        conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 32, 32, 256)   589824      batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 32, 32, 256)   1024        conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_14 (HSwish)              (None, 32, 32, 256)   0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 32, 32, 256)   589824      h_swish_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 32, 32, 256)   1024        conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 32, 32, 128)   0           h_swish_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 32, 32, 640)   0           batch_normalization_25[0][0]     \n",
      "                                                                   batch_normalization_23[0][0]     \n",
      "                                                                   max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 32, 32, 256)   1474560     concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 32, 32, 256)   1024        conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_15 (HSwish)              (None, 32, 32, 256)   0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 32, 32, 256)   589824      h_swish_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 32, 32, 256)   1024        conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_16 (HSwish)              (None, 32, 32, 256)   0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 32, 32, 256)   589824      h_swish_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 32, 32, 256)   1024        conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 32, 32, 256)   589824      batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 32, 32, 256)   1024        conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_17 (HSwish)              (None, 32, 32, 256)   0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 32, 32, 256)   589824      h_swish_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 32, 32, 256)   1024        conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 32, 32, 128)   0           h_swish_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 32, 32, 1152)  0           batch_normalization_31[0][0]     \n",
      "                                                                   batch_normalization_29[0][0]     \n",
      "                                                                   max_pooling2d_5[0][0]            \n",
      "                                                                   h_swish_15[0][0]                 \n",
      "                                                                   h_swish_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 32, 32, 256)   2654208     concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 32, 32, 256)   1024        conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_18 (HSwish)              (None, 32, 32, 256)   0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 16, 16, 512)   1179648     h_swish_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 16, 16, 512)   2048        conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_19 (HSwish)              (None, 16, 16, 512)   0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 16, 16, 512)   2359296     h_swish_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 16, 16, 512)   2048        conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 16, 16, 512)   2359296     batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 16, 16, 512)   2048        conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_20 (HSwish)              (None, 16, 16, 512)   0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 16, 16, 512)   2359296     h_swish_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 16, 16, 512)   2048        conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 16, 16, 256)   0           h_swish_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 16, 16, 1280)  0           batch_normalization_37[0][0]     \n",
      "                                                                   batch_normalization_35[0][0]     \n",
      "                                                                   max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 16, 16, 512)   5898240     concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 16, 16, 512)   2048        conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "h_swish_21 (HSwish)              (None, 16, 16, 512)   0           batch_normalization_38[0][0]     \n",
      "====================================================================================================\n",
      "Total params: 25,085,488\n",
      "Trainable params: 25,071,920\n",
      "Non-trainable params: 13,568\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = DlaKeras(activation_function=\"hswish\", debug=True).build()\n",
    "\n",
    "dummy = np.zeros((1,512,512,3), dtype=float)\n",
    "dummy_shape=m.predict(dummy).shape\n",
    "print(\"Output shape calculated:\", dummy_shape)\n",
    "\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy train: does it train at all ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 80s - loss: 0.2212    \n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 81s - loss: 0.1252    \n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 81s - loss: 0.0740    \n"
     ]
    }
   ],
   "source": [
    "def dummy_train(model:Model,n=50, epochs=3):\n",
    "    rand = np.random.rand(1,512,512,1)\n",
    "    dummy_inputs = np.repeat(np.repeat(rand, n, axis=0),3,axis=-1)\n",
    "    dummy_outputs = np.zeros((n,dummy_shape[1],dummy_shape[2],dummy_shape[3]))\n",
    "    model.fit(dummy_inputs, dummy_outputs, batch_size=4, epochs=epochs)\n",
    "    \n",
    "print(\"Training:\")\n",
    "m = DlaKeras(activation_function=\"hswish\").build()\n",
    "optimizer = SGD(lr=0.1)\n",
    "m.compile(optimizer=optimizer, loss='mse')\n",
    "dummy_train(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

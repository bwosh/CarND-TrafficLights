{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLA-34 in Keras with HSwish as option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, Input, MaxPool2D, Conv2DTranspose\n",
    "from keras.activations import relu\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "    \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReLU, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ReLU, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.relu(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "class HSwish(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(HSwish, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(HSwish, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        six = K.ones_like(x)*6\n",
    "        return x* K.minimum(K.relu(x+3),six)/6\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    def __init__(self, name):\n",
    "        self.root = None\n",
    "        self.tree1 = None\n",
    "        self.tree2 = None\n",
    "        self.level_root = None\n",
    "        self.root_dim = None\n",
    "        self.downsample = None\n",
    "        self.project = None\n",
    "        self.levels = None\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "    def __print_indent(self, indent, text, end='\\n'):\n",
    "        print( \"\".join([' ']*indent), end='')\n",
    "        print(text, end = end)\n",
    "              \n",
    "    def print(self, indent = 0):\n",
    "        self.__print_indent(1 if indent>0 else 0, \"[NODE: \"+str(self.name), end=' ')\n",
    "        self.__print_indent(0, \"lr:\"+str(self.level_root), end=' ')\n",
    "        self.__print_indent(0, \"rdim:\"+str(self.root_dim), end=' ')\n",
    "        self.__print_indent(0, \"downs: \"+str(self.downsample==None), end=' ')\n",
    "        self.__print_indent(0, \"proj: \"+str(self.project==None), end=' ')\n",
    "        self.__print_indent(0, \"levs: \"+str(self.levels), end=']\\n')\n",
    "        \n",
    "        if self.root is None:\n",
    "              self.__print_indent(indent+2, \"R1> None\")\n",
    "        else:\n",
    "              self.__print_indent(indent+2, \"R1> conv,bn,act \")\n",
    "              \n",
    "        if isinstance(self.tree1,Tree):\n",
    "            self.__print_indent(indent+2, \"T1>\", end='')\n",
    "            self.tree1.print(indent=indent+4)\n",
    "        elif self.tree1 is not None:\n",
    "            self.__print_indent(indent+2, \"T1> conv,bn\")\n",
    "\n",
    "        if isinstance(self.tree2,Tree):\n",
    "            self.__print_indent(indent+2, \"T2>\", end='')\n",
    "            self.tree2.print(indent=indent+4)\n",
    "        elif self.tree2 is not None:\n",
    "            self.__print_indent(indent+2, \"T2> conv,bn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DlaKeras():\n",
    "    def __init__(self,  \n",
    "                 levels=[1, 1, 1, 2, 2, 1],\n",
    "                 planes=[16, 32, 64, 128, 256, 512],\n",
    "                 activation_function=\"relu\"):\n",
    "        self.norm_axis = -1\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "        self.base_layer = self._make_simple_block(planes[0], kernel_size=7)\n",
    "        self.level0 = self._make_conv_level(planes[0], levels[0], stride=1)\n",
    "        self.level1 = self._make_conv_level(planes[1], levels[1], stride=2)\n",
    "        \n",
    "        self.level2 = self._make_tree(\"L2_\", levels[2], planes[1], planes[2], level_root=False)\n",
    "        self.level3 = self._make_tree(\"L3_\",levels[3], planes[2], planes[3])\n",
    "        self.level4 = self._make_tree(\"L4_\",levels[4], planes[3], planes[4])\n",
    "        self.level5 = self._make_tree(\"L5_\",levels[5], planes[4], planes[5])\n",
    "        \n",
    "    def _make_tree(self, name, levels, in_planes, planes, stride=2, level_root=True, root_dim=0):\n",
    "        result = Tree(name)\n",
    "        \n",
    "        if root_dim == 0:\n",
    "            root_dim = 2 * planes\n",
    "        if level_root:\n",
    "            root_dim += in_planes\n",
    "        \n",
    "        if levels==1:\n",
    "            result.tree1 = self._make_basic_block(planes, stride)\n",
    "            result.tree2 = self._make_basic_block(planes, 1)\n",
    "        else:\n",
    "            result.tree1 = self._make_tree(name+\"1\",levels-1, in_planes, planes, stride=stride)\n",
    "            result.tree2 = self._make_tree(name+\"2\",levels-1, planes, planes, stride=1, root_dim=root_dim + planes)\n",
    "            \n",
    "        if levels == 1:\n",
    "            result.root = self._make_root(root_dim, planes)   # TODO minor: remove root_dim ?\n",
    "        \n",
    "        result.level_root = level_root\n",
    "        result.root_dim = root_dim\n",
    "        result.levels = levels\n",
    "        if stride > 1:\n",
    "            result.downsample = MaxPool2D(pool_size=(stride, stride), strides=(stride, stride), padding = 'same')\n",
    "            \n",
    "        if in_planes != planes:\n",
    "            result.project = []\n",
    "            result.project.append(Conv2D(filters=planes, kernel_size=1, padding='same', strides=(1,1), use_bias=False))\n",
    "            result.project.append(BatchNormalization(axis=self.norm_axis))    \n",
    "\n",
    "        return result\n",
    "\n",
    "    def _make_root(self, in_planes, planes):\n",
    "        return self._make_simple_block(planes)\n",
    "    \n",
    "    def _make_basic_block(self, planes, stride=1):\n",
    "        layers=[]\n",
    "        \n",
    "        conv1 = Conv2D(filters=planes, kernel_size=3, padding='same', strides=(stride,stride), use_bias=False)\n",
    "        bn1 = BatchNormalization(axis=self.norm_axis)\n",
    "        if self.activation_function == \"hswish\":\n",
    "            activation = HSwish()\n",
    "        else:\n",
    "            activation = ReLU()\n",
    "        conv2 = Conv2D(filters=planes, kernel_size=3, padding='same', strides=(1,1), use_bias=False)\n",
    "        bn2 = BatchNormalization(axis=self.norm_axis)\n",
    "        \n",
    "        layers = [conv1,bn1,activation, conv2, bn2]\n",
    "        return layers\n",
    "    \n",
    "    def _make_simple_block(self, planes, kernel_size=3, stride = 1):\n",
    "        \n",
    "        conv = Conv2D(filters=planes, kernel_size=kernel_size, padding='same', strides=(stride,stride), use_bias=False)\n",
    "        bn = BatchNormalization(axis=self.norm_axis)\n",
    "        if self.activation_function == \"hswish\":\n",
    "            activation = HSwish()\n",
    "        else:\n",
    "            activation = ReLU()\n",
    "        \n",
    "        layers = [conv,bn,activation]\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def _make_conv_level(self, planes, levels, stride = 1):\n",
    "        layers = []\n",
    "        for i in range(levels):\n",
    "            layers.extend(self._make_simple_block(planes, stride = stride))\n",
    "        return layers\n",
    "            \n",
    "    def _build_list(self, x, layers):\n",
    "        for l in layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "    \n",
    "    def _build_root(self, root, *x):\n",
    "        x = list(x)\n",
    "        conv = root[0]\n",
    "        bn = root[1]\n",
    "        act = root[2]\n",
    "        \n",
    "        x = concatenate(x, axis = self.norm_axis)\n",
    "        x = conv(x)\n",
    "        x = bn(x)\n",
    "        x = act(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _build_tree(self,x, tree, children=None, residual=None):\n",
    "        if not isinstance(tree, Tree):\n",
    "            return self._build_list(x,tree)\n",
    "        \n",
    "        \n",
    "        children = [] if children is None else children\n",
    "        bottom = tree.downsample(x) if tree.downsample else x\n",
    "        residual = self._build_list(bottom,tree.project) if tree.project else bottom\n",
    "        \n",
    "        if tree.level_root:\n",
    "            children.append(bottom)\n",
    "\n",
    "        x1 = self._build_tree(x, tree.tree1, residual=residual)\n",
    "\n",
    "        if tree.levels == 1:\n",
    "            x2 = self._build_tree(x1,tree.tree2)\n",
    "            x = self._build_root(tree.root, x2, x1, *children)\n",
    "        else:\n",
    "            children.append(x1)\n",
    "            x = self._build_tree(x1, tree.tree2, children=children)\n",
    "        return x\n",
    "        \n",
    "    def build(self, inputs):\n",
    "        x = self._build_list(inputs, self.base_layer)\n",
    "        l0 = self._build_list(x, self.level0)\n",
    "        l1 = self._build_list(l0, self.level1)\n",
    "        l2 = self._build_tree(l1, self.level2)\n",
    "        l3 = self._build_tree(l2, self.level3)\n",
    "        l4 = self._build_tree(l3, self.level4)\n",
    "        l5 = self._build_tree(l4, self.level5)\n",
    "        return [l0,l1,l2,l3,l4,l5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def build(self, x):\n",
    "        return x\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return self.build(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdaUp():\n",
    "    def __init__(self, node_kernel, out_dim, planes, up_factors):\n",
    "        self.planes = planes\n",
    "        self.projs = {}\n",
    "        self.ups = {}\n",
    "        self.nodes = {}\n",
    "        \n",
    "        for i, c in enumerate(planes):\n",
    "            if c == out_dim:\n",
    "                proj = [Identity()]\n",
    "            else:\n",
    "                proj = [Conv2D(filters=out_dim, kernel_size=1, padding='same', strides=(1,1), use_bias=False),\n",
    "                        BatchNormalization(axis=-1),\n",
    "                        ReLU()]\n",
    "            f = int(up_factors[i])\n",
    "            if f == 1:\n",
    "                up = Identity()\n",
    "            else:\n",
    "                up = Conv2DTranspose(out_dim, kernel_size= f * 2, strides=f, padding=\"same\", use_bias=False)\n",
    "                \n",
    "            self.projs[i] = proj\n",
    "            self.ups[i] = up\n",
    "            \n",
    "        for i in range(1, len(planes)):\n",
    "            node = [Conv2D(out_dim, kernel_size=node_kernel, strides=1,padding=\"same\", use_bias=False),\n",
    "                    BatchNormalization(axis=-1),\n",
    "                    ReLU()]\n",
    "            self.nodes[i] = node\n",
    "            \n",
    "    def _build_list(self, x, layers):\n",
    "        for l in layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "    \n",
    "    def build(self, layers):\n",
    "        assert(len(self.planes) == len(layers))\n",
    "        layers = list(layers)\n",
    "        for i, l in enumerate(layers):\n",
    "            upsample = self.ups[i]\n",
    "            project = self.projs[i]\n",
    "            \n",
    "            layers[i] = upsample(self._build_list(l, project))\n",
    "            \n",
    "        x = layers[0]\n",
    "        y = []\n",
    "        for i in range(1, len(layers)):\n",
    "            node = self.nodes[i]\n",
    "            concatenated = concatenate([x, layers[i]], axis=-1)\n",
    "            x = self._build_list(concatenated, node)\n",
    "            y.append(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DlaUp():\n",
    "    def __init__(self, planes, scales):\n",
    "        self.planes = planes\n",
    "        self.scales = np.array(scales, dtype=int)\n",
    "        self.in_planes = list(planes)\n",
    "        self.idas ={}\n",
    "        \n",
    "        for i in range(len(self.planes) - 1):\n",
    "            j = -i - 2\n",
    "            self.idas[i] = IdaUp(3, self.planes[j], self.in_planes[j:], self.scales[j:] // self.scales[j])\n",
    "            self.scales[j + 1:] = self.scales[j]\n",
    "            self.in_planes[j + 1:] = [self.planes[j] for _ in self.planes[j + 1:]]\n",
    "    \n",
    "    def build(self, layers):\n",
    "        layers = list(layers)\n",
    "        assert len(layers) > 1\n",
    "        for i in range(len(layers) - 1):\n",
    "            ida = self.idas[i]\n",
    "            x, y = ida.build(layers[-i - 2:])\n",
    "            layers[-i - 1:] = y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DlaSeg():\n",
    "    def __init__(self, down_ratio=4, \n",
    "                 head_conv=256,\n",
    "                 input_shape = (512,512,3),  \n",
    "                 levels=[1, 1, 1, 2, 2, 1],\n",
    "                 planes=[16, 32, 64, 128, 256, 512],\n",
    "                 activation_function=\"relu\"):\n",
    "        # Params\n",
    "        assert down_ratio in [2, 4, 8, 16]\n",
    "        self.input = Input(shape = input_shape)\n",
    "        self.base = DlaKeras(levels=levels, planes=planes, activation_function=activation_function)\n",
    "        self.heads = heads={'hm': 1, 'wh': 2}\n",
    "        \n",
    "        self.first_level = int(np.log2(down_ratio))\n",
    "        scales = [2 ** i for i in range(len(planes[self.first_level:]))]\n",
    "        self.planes = planes\n",
    "        \n",
    "        # Up\n",
    "        self.dla_up = DlaUp(planes[self.first_level:], scales=scales)\n",
    "        \n",
    "        # Hed\n",
    "        self.head_layers = {}\n",
    "        self.head_conv = head_conv\n",
    "        for head in heads:\n",
    "            self.head_layers[head] = self.add_head(head)\n",
    "            \n",
    "    def add_head(self, head):\n",
    "        layers = []\n",
    "        classes = self.heads[head]\n",
    "        if self.head_conv > 0:\n",
    "            layers.append(Conv2D(self.head_conv, kernel_size=(3,3), padding=\"same\", use_bias=True))\n",
    "            layers.append(ReLU()),\n",
    "            \n",
    "        layers.append(Conv2D(classes, kernel_size=(1,1), strides=(1,1), padding='same', use_bias=True ))\n",
    "\n",
    "        return layers\n",
    "    \n",
    "    def _build_list(self, x, layers):\n",
    "        for l in layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "    \n",
    "    def build(self):\n",
    "        inputs = self.input\n",
    "        levels = self.base.build(inputs)\n",
    "        x = self.dla_up.build(levels[self.first_level:])\n",
    "            \n",
    "        outputs = []\n",
    "        for head in self.head_layers:\n",
    "            outputs.append(self._build_list(x, self.head_layers[head]))\n",
    "        return Model(inputs = inputs, outputs=outputs)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape calculated: (1, 128, 128, 1) (1, 128, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "m = DlaSeg().build()\n",
    "\n",
    "dummy = np.zeros((1,512,512,3), dtype=float)\n",
    "dummy_result = m.predict(dummy)\n",
    "dummy_hm, dummy_wh = dummy_result\n",
    "\n",
    "\n",
    "print(\"Output shape calculated:\", dummy_hm.shape, dummy_wh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy train: does it train at all ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 45s - loss: 9.7498 - conv2d_1010_loss: 7.2756 - conv2d_1012_loss: 2.4742    \n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 44s - loss: 0.0682 - conv2d_1010_loss: 0.0251 - conv2d_1012_loss: 0.0431    \n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 44s - loss: 0.0148 - conv2d_1010_loss: 0.0027 - conv2d_1012_loss: 0.0121    \n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 44s - loss: 0.0047 - conv2d_1010_loss: 2.9960e-04 - conv2d_1012_loss: 0.0044    \n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 44s - loss: 0.0021 - conv2d_1010_loss: 4.5553e-05 - conv2d_1012_loss: 0.0021    \n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 44s - loss: 0.0013 - conv2d_1010_loss: 1.8105e-05 - conv2d_1012_loss: 0.0013    \n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 44s - loss: 0.0010 - conv2d_1010_loss: 1.4885e-05 - conv2d_1012_loss: 0.0010    \n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 44s - loss: 9.0048e-04 - conv2d_1010_loss: 1.4281e-05 - conv2d_1012_loss: 8.8620e-04    \n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 44s - loss: 8.1760e-04 - conv2d_1010_loss: 1.3978e-05 - conv2d_1012_loss: 8.0362e-04    \n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 44s - loss: 7.5749e-04 - conv2d_1010_loss: 1.3713e-05 - conv2d_1012_loss: 7.4377e-04    \n"
     ]
    }
   ],
   "source": [
    "def dummy_train(model:Model,n=20, epochs=10):\n",
    "    rand = np.random.rand(1,512,512,1)\n",
    "    dummy_inputs = np.repeat(np.repeat(rand, n, axis=0),3,axis=-1)\n",
    "    dummy_outputs_hm = np.zeros((n,dummy_hm.shape[1],dummy_hm.shape[2],dummy_hm.shape[3]))\n",
    "    dummy_outputs_wh = np.zeros((n,dummy_wh.shape[1],dummy_wh.shape[2],dummy_wh.shape[3]))\n",
    "    return model.fit(dummy_inputs, [dummy_outputs_hm, dummy_outputs_wh], batch_size=4, epochs=epochs)\n",
    "    \n",
    "print(\"Training:\")\n",
    "m = DlaSeg().build()\n",
    "optimizer = SGD(lr=0.1)\n",
    "m.compile(optimizer=optimizer, loss='mse')\n",
    "dummy_result = dummy_train(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fccea1c03c8>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(dummy_result.history['loss'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
